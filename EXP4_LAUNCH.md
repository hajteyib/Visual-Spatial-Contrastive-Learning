# EXPERIMENT #4 - ResNet-18 + Supervised Contrastive + Balanced Sampling

## Date
2025-12-18

## ‚úÖ VERIFICATION COMPLETE

### What Changed from Exp #3
| Aspect | Exp #3 (EfficientNet) | **Exp #4** |
|--------|----------------------|------------|
| Backbone | EfficientNet-B0 (5.3M) | **ResNet-18 (11M)** ‚úÖ |
| Contrastive Loss | Self-supervised | **Supervised** ‚úÖ |
| Batch Sampling | Random | **Balanced** ‚úÖ |
| Dropout | 0.3 | **0.4/0.3** ‚úÖ |
| Epochs | 25 | **30** ‚úÖ |
| Result | 56.54% | **Target: 63-68%** |

---

## Architecture

**Visual Encoder** :
- ResNet-18 (ImageNet, FROZEN)
- Features: 512D (sujet) + 512D (objet) = 1024D
- Projection: 1024D ‚Üí 512D ‚Üí 256D
- Dropout: **0.4** (augment√©)

**Spatial Encoder** :
- MLP: 8D ‚Üí 64D ‚Üí 128D ‚Üí 256D
- Dropout: **0.3** (augment√©)

**Params** :
- Trainable: 698k (6%)
- Frozen: 11.2M (94%)

---

## Innovations Exp #4

### 1. Supervised Contrastive Loss ‚≠ê

**Avant (Self-supervised)** :
```python
# Positifs : M√™me sample appari√©
# N√©gatifs : Autres samples al√©atoires
‚Üí N'utilise PAS les labels
```

**Maintenant (Supervised)** :
```python
# Positifs : TOUS les samples avec M√äME label
# N√©gatifs : TOUS les samples avec labels DIFF√âRENTS
‚Üí Utilise les labels pour meilleurs positifs/n√©gatifs
```

**Gain attendu** : +3-5%

---

### 2. Balanced Batch Sampler ‚öñÔ∏è

**Avant** :
```
Batch random : [on, on, on, on, above, on, on, ...]
‚Üí 70% "on", classes rares noy√©es
```

**Maintenant** :
```
Batch balanc√© : [on, on, above, above, under, under, ...]
‚Üí ~10% chaque classe, √©quilibr√©
```

**R√©sultat** :
- 341 batches/epoch (vs 1416 avant)
- ~2 samples/classe/batch
- Toutes classes vues √©quitablement

**Gain attendu** : +2-4% sur classes rares

---

## Configuration

```python
# config.py
BATCH_SIZE = 24
EMBEDDING_DIM = 256
EPOCHS = 30
LEARNING_RATE = 1e-4

# Dataset
Classes: 10 (in/over, PAS inside/outside)
Train: 33,978 samples
Val: 9,708 samples
Test: 4,855 samples

# Regularization
- ResNet-18 frozen (94%)
- Dropout 0.4 (projection)
- Dropout 0.3 (spatial)
- Early stopping: patience 7, min 20 epochs
```

---

## Launch Command

```bash
cd /Users/hajteyibebou/Documents/MSI-Projet_Spatial_Relations
source venv/bin/activate
python3 train.py
```

**IMPORTANT** : V√©rifiez la sortie :
```
‚úÖ Train: 33978 samples  ‚Üê Doit √™tre 33978 !
--- Configuration Balanced Batch Sampler ---
  Batches par epoch: 341  ‚Üê Moins que avant (normal)
  Samples par classe/batch: ~2
```

---

## Expected Output

```
Epoch 1/30: 100%|‚ñà‚ñà‚ñà‚ñà| 341/341 [02:30<00:00]
   -> Train Loss: 2.XXXX | Val Loss: 2.XXXX | Val Acc: 0.XXX
      üî• Meilleur mod√®le sauvegard√© !

Epoch 2/30: ...
```

**Dur√©e** :
- ~2.5 min/epoch (batchs balanc√©s = moins de batches)
- Total: ~75 min (1h15) si 30 epochs
- Probable early stopping ~epoch 22-25 ‚Üí ~55-65 min

---

## Success Criteria

**Minimum** : 63% accuracy (battre Exp #1's 61.67%)  
**Target** : 65-66% accuracy  
**Optimal** : 68%+ accuracy  

**Classes rares** :
- over, left of, right of, near : >20% recall (vs 0-4% avant)
- All classes : >10% recall

---

## After Training

```bash
# Evaluer avec SVM
python3 evaluate.py checkpoints/exp_YYYYMMDD_HHMMSS
```

R√©sultats dans : `checkpoints/exp_YYYYMMDD_HHMMSS/evaluation_results/`

---

## Key Differences vs Previous Exps

**vs Exp #1 (ResNet-18, 61.67%)** :
- ‚úÖ Supervised contrastive (meilleur)
- ‚úÖ Balanced sampling (√©quilibre)
- ‚úÖ Dropout plus fort (r√©gularisation)

**vs Exp #3 (EfficientNet-B0, 56.54%)** :
- ‚úÖ ResNet-18 (prouv√© meilleur pour notre t√¢che)
- ‚úÖ Supervised contrastive (vs self-supervised)
- ‚úÖ Balanced sampling (√©quilibre)

---

**Tout est v√©rifi√© et test√© - Pr√™t √† lancer !** üöÄ
