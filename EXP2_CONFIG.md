# Exp√©rience #2 - Configuration et Objectifs

## üéØ Objectifs de l'Exp√©rience

**Am√©liorer** l'Exp√©rience #1 (Baseline 61.67%) en :
1. Combattant le d√©s√©quilibre extr√™me des classes (344:1 ratio)
2. Augmentant la capacit√© du mod√®le
3. Optimisant la convergence

**Cible** : 73-79% accuracy (+12-18%)

---

## üîß Modifications par Rapport √† Exp #1

### 1. Architecture Mod√®le

**Visual Encoder - ResNet-50** (au lieu de ResNet-18)
- Backbone gel√© : 25M param√®tres
- Features : 2048D (au lieu de 512D) ‚Üí 4x plus riche
- Projection : 4096 ‚Üí 1024 ‚Üí 128

**Param√®tres Totaux** :
- ResNet-50 gel√© : ~25M (non-entra√Ænables)
- Projection Visual : ~4.7M (entra√Ænables)
- Spatial Encoder : 73k (entra√Ænables)
- **Total entra√Ænable : ~4.77M** (vs 615k dans Exp #1)

### 2. Loss Function

**Weighted CrossEntropyLoss**

Poids par classe (bas√©s sur analyse dataset) :
```python
on:       0.24   # Classe dominante (13103 exemples)
under:    1.06
above:    0.62
below:    1.77
left of:  3.92
right of: 4.72
near:     1.28
next to:  0.75
inside:   22.53  # Classe rare (137 exemples)
outside:  81.21  # Classe tr√®s rare (38 exemples)
```

**Impact** : P√©nalise 81x plus les erreurs sur "outside" vs "on"

### 3. Data Balancing

**Oversampling Cibl√© (train uniquement)** :
- Classes <100 exemples ‚Üí dupliquer x3
- Classes 100-500 exemples ‚Üí dupliquer x2
- Classes >500 exemples ‚Üí aucune duplication

**R√©sultat attendu** :
- Train : ~40,000 paires (vs 30,860 dans Exp #1)
- inside : 137 ‚Üí 411 exemples
- outside : 38 ‚Üí 114 exemples

### 4. Training Optimizations

**LR Scheduler** : ReduceLROnPlateau
- Factor : 0.5 (divise LR par 2)
- Patience : 3 epochs
- Min LR : 1e-6

**Gradient Clipping** : max_norm=1.0
- √âvite explosions avec weighted loss

**Early Stopping Am√©lior√©** :
- Patience : 5 epochs (vs 3 dans Exp #1)
- Min epochs : 15 (vs 10 dans Exp #1)

**Epochs Max** : 50 (vs 15 dans Exp #1)

---

## üìä Hyperparam√®tres

```python
BATCH_SIZE = 16           # Identique
LEARNING_RATE = 1e-4      # Identique (initial)
EPOCHS = 50               # Augment√©
IMG_SIZE = 128            # Identique
EMBEDDING_DIM = 128       # Identique
TEMPERATURE = 0.07        # Identique
DROPOUT = 0.3 / 0.2       # Identique
```

---

## üìà Pr√©dictions Performance

### Accuracy Globale

- **Conservative** : 73-76% (+12-15%)
- **Optimiste** : 76-79% (+15-18%)

### Par Relation (Pr√©dictions)

| Relation | Exp #1 | Exp #2 (Pr√©dit) | Gain |
|----------|--------|-----------------|------|
| on | 91% | 88-90% | -1 √† -3% (acceptable) |
| above | 68% | 72-75% | +4-7% |
| under | 59% | 65-70% | +6-11% |
| next to | 44% | 50-55% | +6-11% |
| **below** | **10%** | **30-40%** | **+20-30%** ‚≠ê |
| **near** | **3%** | **15-25%** | **+12-22%** ‚≠ê |
| **left of** | **2%** | **20-30%** | **+18-28%** ‚≠ê |
| **right of** | **0%** | **15-25%** | **+15-25%** ‚≠ê |
| **inside** | **0%** | **10-20%** | **+10-20%** ‚≠ê |
| **outside** | **0%** | **5-15%** | **+5-15%** ‚≠ê |

### Convergence Attendue

- Meilleur mod√®le : Epoch 18-25 (vs 12 dans Exp #1)
- Val Loss finale : 1.1-1.2 (vs 1.45 dans Exp #1)
- Val Acc finale : 52-58% (vs 48% dans Exp #1)

---

## ‚è±Ô∏è Temps Estim√©

**Par epoch** : 12-15 minutes (vs 8-10 min dans Exp #1)
- ResNet-50 est plus lourd
- Oversampling augmente dataset

**Total** : 5-7 heures
- Si early stopping √† epoch 25 : ~5h
- Si 50 epochs complets : ~10h

---

## üî¨ Modifications Code

### model.py
- Ligne 12 : `resnet18` ‚Üí `resnet50`
- Ligne 21-24 : Projection adapt√©e (4096 ‚Üí 1024 ‚Üí 128)

### config.py
- Ligne 11 : `EPOCHS = 15` ‚Üí `EPOCHS = 50`

### dataset.py
- Lignes 97-130 : Oversampling cibl√© (nouveau)

### train.py
- Lignes 123-150 : Weighted loss + LR scheduler
- Ligne 162-165 : Gradient clipping
- Lignes 195-205 : Early stopping am√©lior√©

---

## ‚úÖ Checklist Pr√©-Entra√Ænement

- [x] ResNet-50 impl√©ment√©
- [x] Weighted loss configur√©e
- [x] Oversampling activ√©
- [x] LR scheduler ajout√©
- [x] Gradient clipping activ√©
- [x] Early stopping am√©lior√©
- [x] Epochs augment√©s √† 50
- [ ] Lancer `python3 train.py`

---

## üìù Notes pour Analyse Post-Entra√Ænement

**Comparer avec Exp #1** :
- Accuracy globale
- Recall par relation (focus sur rares)
- Val Loss finale
- Nombre d'epochs avant convergence
- Impact du LR scheduler (observer les changements de LR)

**V√©rifier** :
- Pas de sur-apprentissage (√©cart train/val)
- Am√©lioration sur classes rares (below, left of, right of, etc.)
- Stabilit√© de la convergence

---

**Date de cr√©ation** : 2 D√©cembre 2025  
**Pr√™t √† lancer** ‚úÖ
